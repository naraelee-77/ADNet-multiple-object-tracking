# Multiple Object Tracking

- In this project we use deep reinforcement learning for multiple object tracking
- Datasets used:
  - Wright-Patterson Air Force Base (WPAFB)/Large Area Image Recorder (LAIR): High altitude grayscale videos of cars taken by UAVs/drones. Each frame is stitched/cropped from multiple drones, so effectively nearly still-camera [[Link]] (https://www.sdms.afrl.af.mil/index.php?collection=wpafb2009)
  - Multiple Object Tracking Challenge Benchmark (MOT): Videos of pedestrians on the street. Includes still-camera and moving-camera, and multiple perspectives [[Link]] (https://motchallenge.net/)

### Participation in REU
This was a project worked on during the Research Experience for Undergraduates (REU) program at the University of Central Florida's Center of Research for Computer Vision (UCF CRCV) in Summer 2018. [[Link to Page]](http://crcv.ucf.edu/REU/2018/narae)

### Paper
Here is the final version of the paper written for the project [[Paper]](https://drive.google.com/file/d/1D0qkf4voPLldTG2PBcHFiAGDAtxWEL27/view?usp=sharing)

### Literature Cited
- ADNet-cvpr2017: Action-Decision Networks for Visual Tracking with Deep Reinforcement Learning [[Repository]](https://github.com/hellbell/ADNet)


